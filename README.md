<div align="center">
  
  # SHAMS TABREZ KHAN
  
  ### AI Engineer | Machine Learning Researcher | Computer Vision Specialist
  
 [![Typing SVG](https://readme-typing-svg.demolab.com?font=Fira+Code&weight=600&size=26&duration=2800&pause=800&color=00F7FF&center=true&vCenter=true&width=800&lines=Building+Scalable+AI+Systems;Training+LLMs+From+Scratch;Computer+Vision+%7C+Generative+AI;MLOps+%7C+Production+ML)](https://git.io/typing-svg)
</div>

---

## About Me

> *"Building intelligence, one model at a time."*

I'm an AI Engineer specializing in **Computer Vision** and **Large Language Models**. My passion lies in architecting efficient neural networks and pushing the boundaries of what's possible with deep learning.


---

## Core Competencies

<div align="center">

| Domain | Expertise | Current Projects |
|--------|-----------|------------------|
| **LLM Engineering** | Architecture Design, Fine-tuning, RLHF, Quantization | Training 1B param model from scratch |
| **Computer Vision** | Object Detection, Segmentation, GANs, Vision Transformers | Real-time detection system |
| **MLOps** | Distributed Training, Model Serving, Optimization | LLM deployment pipeline |
| **Research** | Attention Mechanisms, Efficient Architectures | Novel KV-cache design |

</div>

---

## Technical Arsenal

### **Core ML/DL Stack**
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white)
![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=for-the-badge&logo=Keras&logoColor=white)
![JAX](https://img.shields.io/badge/JAX-%23000000.svg?style=for-the-badge&logo=jax&logoColor=white)
![Hugging Face](https://img.shields.io/badge/ðŸ¤—%20Hugging%20Face-FFD21E?style=for-the-badge)

### **LLM & Generative AI**
![LangChain](https://img.shields.io/badge/LangChain-121212?style=for-the-badge&logo=chainlink&logoColor=white)
![LlamaIndex](https://img.shields.io/badge/LlamaIndex-FF6B6B?style=for-the-badge)
![Transformers](https://img.shields.io/badge/Transformers-FFB71B?style=for-the-badge)
![LoRA](https://img.shields.io/badge/LoRA-PEFT-9B59B6?style=for-the-badge)
![QLoRA](https://img.shields.io/badge/QLoRA-4-bit-27AE60?style=for-the-badge)

### **Computer Vision**
![OpenCV](https://img.shields.io/badge/OpenCV-%23white.svg?style=for-the-badge&logo=opencv&logoColor=white)
![Detectron2](https://img.shields.io/badge/Detectron2-FB533B?style=for-the-badge&logo=meta&logoColor=white)
![YOLO](https://img.shields.io/badge/YOLO-00FFFF?style=for-the-badge)
![ViT](https://img.shields.io/badge/Vision%20Transformers-663399?style=for-the-badge)

### **MLOps & Production**
![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Kubernetes](https://img.shields.io/badge/Kubernetes-326CE5?style=for-the-badge&logo=kubernetes&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?style=for-the-badge&logo=fastapi&logoColor=white)
![MLflow](https://img.shields.io/badge/MLflow-%23d9ead3.svg?style=for-the-badge&logo=numpy&logoColor=blue)
![Weights & Biases](https://img.shields.io/badge/W&B-FFBE00?style=for-the-badge&logo=weightsandbiases&logoColor=black)

### **Data Science Stack**
![NumPy](https://img.shields.io/badge/NumPy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white)
![cuDF](https://img.shields.io/badge/cuDF-76B900?style=for-the-badge&logo=nvidia&logoColor=white)
![Dask](https://img.shields.io/badge/Dask-FDA061?style=for-the-badge&logo=dask&logoColor=white)



## Featured Projects

### **LLM Architecture & Training**
project: "Efficient-LLM-From-Scratch"
status:  In Development
parameters: 1.2B
architecture:
  - Multi-Query Attention
  - SwiGLU Activation
  - Rotary Embeddings
  - Flash Attention v2
training:
  tokens: 100B
  hardware: 8x A100 80GB
  framework: PyTorch + FSDP
features:
  - Custom tokenizer
  - Efficient KV-cache
  - Quantization ready


### **Computer Vision Systems**

project: "Real-time Object Detection Pipeline"
status: Production
tech_stack: [YOLOv8, TensorRT, Triton Server]
optimization:
  - FP16 precision
  - TensorRT optimization
  - Batch processing
deployment: 
  - Kubernetes cluster
  - Auto-scaling
  - <10ms latency


### **Fine-tuning Studio**
project: "LLM-Fine-tuning-Framework"
status: Active
techniques:
  - LoRA/QLoRA
  - Prefix Tuning
  - P-Tuning v2
use_cases:
  - Domain adaptation
  - Instruction tuning
  - RLHF pipeline
efficiency:
  - 4-bit quantization
  - Gradient checkpointing
  - Flash attention


---

## Research & Development

### Current Research Focus
-  **Efficient Attention Mechanisms** - Reducing KV-cache memory footprint
-  **Neural Architecture Search** - Automated ViT architecture discovery
-  **Model Compression** - 2-bit quantization for LLMs
-  **Few-shot Learning** - Meta-learning approaches for CV

### Reading & Implementing
"FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness"
"LLaMA: Open and Efficient Foundation Language Models"
"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
"QLoRA: Efficient Finetuning of Quantized LLMs"


---

## Current Focus & Goals

mindmap
  root((2024-2025))
    LLM Development
      Train 3B model from scratch
      Implement MoE architecture
      Release open-source weights
    Computer Vision
      Real-time video understanding
      Multi-modal models
      Edge deployment
    MLOps
      Distributed training pipeline
      Automated model serving
      Monitoring & observability
    Community
      Open-source projects
      Technical writing
      Mentoring


---

## Weekly Development Breakdown

PyTorch/TensorFlow    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘   78% 
Research Papers       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘   65% 
Model Optimization    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘   60%  
Architecture Design   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘   52%  
Deployment/MLOps      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘   45%  


---

## Let's Connect!

<div align="center">

[![LinkedIn](https://img.shields.io/badge/LinkedIn-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/shamskhan404)
[![GitHub](https://img.shields.io/badge/GitHub-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/shamskhan404)

**Open for research collaborations and engineering roles!**

</div>

---
